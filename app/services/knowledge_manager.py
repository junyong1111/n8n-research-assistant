"""
ì§€ì‹ ìƒíƒœ ê´€ë¦¬ ì„œë¹„ìŠ¤ (JSON ê¸°ë°˜)
"""
import json
import os
from typing import Dict, List, Optional
from datetime import datetime
from pathlib import Path
from app.utils.logger import get_logger

logger = get_logger()


class KnowledgeManager:
    """ë…¼ë¬¸ ë¦¬ì„œì¹˜ ì§€ì‹ ìƒíƒœ ê´€ë¦¬"""

    def __init__(self, storage_path: str = "data/research_knowledge.json"):
        """
        ì´ˆê¸°í™”

        Args:
            storage_path: JSON ì €ì¥ ê²½ë¡œ
        """
        self.storage_path = Path(storage_path)
        self.storage_path.parent.mkdir(parents=True, exist_ok=True)

        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
        if not self.storage_path.exists():
            self._initialize_storage()

        logger.info(f"âœ… Knowledge Manager ì´ˆê¸°í™”: {self.storage_path}")

    def _initialize_storage(self):
        """ë¹ˆ ì €ì¥ì†Œ ì´ˆê¸°í™”"""
        initial_data = {
            "version": "1.0",
            "created_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat(),
            "topics": {}
        }
        self._save_data(initial_data)
        logger.info("ğŸ“ ìƒˆ ì§€ì‹ ì €ì¥ì†Œ ìƒì„±")

    def _load_data(self) -> Dict:
        """JSON ë°ì´í„° ë¡œë“œ"""
        try:
            with open(self.storage_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {"version": "1.0", "topics": {}}

    def _save_data(self, data: Dict):
        """JSON ë°ì´í„° ì €ì¥"""
        try:
            data["last_updated"] = datetime.now().isoformat()
            with open(self.storage_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            logger.info("ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            raise

    def get_topic_knowledge(self, topic_name: str) -> Optional[Dict]:
        """
        ì£¼ì œë³„ ì§€ì‹ ìƒíƒœ ì¡°íšŒ

        Args:
            topic_name: ì£¼ì œëª… (ì˜ˆ: "gnn_recommendation")

        Returns:
            ì£¼ì œ ì§€ì‹ ì •ë³´ ë˜ëŠ” None
        """
        data = self._load_data()
        topic_key = self._normalize_topic_name(topic_name)
        return data["topics"].get(topic_key)

    def create_topic(self, topic_name: str, knowledge_state: str = "beginner") -> Dict:
        """
        ìƒˆ ì£¼ì œ ìƒì„±

        Args:
            topic_name: ì£¼ì œëª…
            knowledge_state: ì´ˆê¸° ì§€ì‹ ìƒíƒœ (beginner/intermediate/experienced)

        Returns:
            ìƒì„±ëœ ì£¼ì œ ì •ë³´
        """
        data = self._load_data()
        topic_key = self._normalize_topic_name(topic_name)

        if topic_key in data["topics"]:
            logger.warning(f"âš ï¸ ì£¼ì œê°€ ì´ë¯¸ ì¡´ì¬í•¨: {topic_name}")
            return data["topics"][topic_key]

        new_topic = {
            "topic_name": topic_name,
            "knowledge_state": {
                "state": knowledge_state,
                "foundation_papers_read": 0,
                "core_papers_read": 0,
                "recent_papers_read": 0,
                "progress_percentage": 0.0
            },
            "foundation_papers": [],
            "core_papers": [],
            "recent_papers": [],
            "reading_order": [],
            "last_updated": datetime.now().isoformat(),
            "search_history": []
        }

        data["topics"][topic_key] = new_topic
        self._save_data(data)

        logger.info(f"âœ… ìƒˆ ì£¼ì œ ìƒì„±: {topic_name} (ìƒíƒœ: {knowledge_state})")
        return new_topic

    def add_papers_to_topic(
        self,
        topic_name: str,
        papers: List[Dict],
        category: str = "recent"  # foundation/core/recent
    ) -> Dict:
        """
        ì£¼ì œì— ë…¼ë¬¸ ì¶”ê°€

        Args:
            topic_name: ì£¼ì œëª…
            papers: ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
            category: ì¹´í…Œê³ ë¦¬ (foundation/core/recent)

        Returns:
            ì—…ë°ì´íŠ¸ëœ ì£¼ì œ ì •ë³´
        """
        data = self._load_data()
        topic_key = self._normalize_topic_name(topic_name)

        # ì£¼ì œê°€ ì—†ìœ¼ë©´ ìƒì„±
        if topic_key not in data["topics"]:
            data["topics"][topic_key] = self.create_topic(topic_name)

        topic = data["topics"][topic_key]
        category_key = f"{category}_papers"

        if category_key not in topic:
            logger.error(f"âŒ ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬: {category}")
            return topic

        # ì¤‘ë³µ ì œê±° (paper_id ê¸°ì¤€)
        existing_ids = {p["id"] for p in topic[category_key]}
        new_papers = [p for p in papers if p["id"] not in existing_ids]

        if new_papers:
            topic[category_key].extend(new_papers)
            topic["last_updated"] = datetime.now().isoformat()
            self._save_data(data)
            logger.info(f"âœ… ë…¼ë¬¸ {len(new_papers)}ê°œ ì¶”ê°€: {topic_name} > {category}")
        else:
            logger.info(f"â„¹ï¸ ì¶”ê°€í•  ìƒˆ ë…¼ë¬¸ ì—†ìŒ (ëª¨ë‘ ì¤‘ë³µ)")

        return topic

    def mark_paper_as_read(self, topic_name: str, paper_id: str, category: str):
        """ë…¼ë¬¸ì„ ì½ìŒìœ¼ë¡œ í‘œì‹œ"""
        data = self._load_data()
        topic_key = self._normalize_topic_name(topic_name)

        if topic_key not in data["topics"]:
            logger.error(f"âŒ ì£¼ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {topic_name}")
            return

        topic = data["topics"][topic_key]
        category_key = f"{category}_papers"

        # ë…¼ë¬¸ ì°¾ì•„ì„œ status ì—…ë°ì´íŠ¸
        for paper in topic.get(category_key, []):
            if paper["id"] == paper_id:
                paper["status"] = "read"

                # ì½ì€ ë…¼ë¬¸ ìˆ˜ ì—…ë°ì´íŠ¸
                count_key = f"{category}_papers_read"
                topic["knowledge_state"][count_key] = topic["knowledge_state"].get(count_key, 0) + 1

                # ì§„í–‰ë¥  ê³„ì‚°
                self._update_progress(topic)

                self._save_data(data)
                logger.info(f"âœ… ë…¼ë¬¸ ì½ìŒ í‘œì‹œ: {paper_id}")
                break

    def _update_progress(self, topic: Dict):
        """ì§„í–‰ë¥  ê³„ì‚°"""
        state = topic["knowledge_state"]
        total_papers = (
            len(topic.get("foundation_papers", [])) +
            len(topic.get("core_papers", [])) +
            len(topic.get("recent_papers", []))
        )

        if total_papers == 0:
            state["progress_percentage"] = 0.0
            return

        read_papers = (
            state.get("foundation_papers_read", 0) +
            state.get("core_papers_read", 0) +
            state.get("recent_papers_read", 0)
        )

        state["progress_percentage"] = round((read_papers / total_papers) * 100, 2)

        # ìƒíƒœ ìë™ ì „í™˜
        if state["progress_percentage"] >= 80:
            if state["state"] == "beginner":
                state["state"] = "intermediate"
                logger.info("ğŸ‰ ìƒíƒœ ì „í™˜: beginner â†’ intermediate")
            elif state["state"] == "intermediate":
                state["state"] = "experienced"
                logger.info("ğŸ‰ ìƒíƒœ ì „í™˜: intermediate â†’ experienced")

    def get_unread_papers(self, topic_name: str) -> Dict[str, List[Dict]]:
        """ì½ì§€ ì•Šì€ ë…¼ë¬¸ ì¡°íšŒ"""
        topic = self.get_topic_knowledge(topic_name)
        if not topic:
            return {"foundation": [], "core": [], "recent": []}

        result = {}
        for category in ["foundation", "core", "recent"]:
            papers = topic.get(f"{category}_papers", [])
            unread = [p for p in papers if p.get("status") != "read"]
            result[category] = unread

        return result

    def _normalize_topic_name(self, topic_name: str) -> str:
        """ì£¼ì œëª… ì •ê·œí™” (ì†Œë¬¸ì, ê³µë°± ì œê±°)"""
        return topic_name.lower().replace(" ", "_")

    def get_all_topics(self) -> List[str]:
        """ëª¨ë“  ì£¼ì œ ëª©ë¡ ì¡°íšŒ"""
        data = self._load_data()
        return list(data["topics"].keys())

    def add_search_history(self, topic_name: str, search_info: Dict):
        """ê²€ìƒ‰ ì´ë ¥ ì¶”ê°€"""
        data = self._load_data()
        topic_key = self._normalize_topic_name(topic_name)

        if topic_key not in data["topics"]:
            self.create_topic(topic_name)
            data = self._load_data()

        topic = data["topics"][topic_key]
        if "search_history" not in topic:
            topic["search_history"] = []

        search_record = {
            "searched_at": datetime.now().isoformat(),
            **search_info
        }

        topic["search_history"].append(search_record)
        self._save_data(data)
        logger.info(f"ğŸ“ ê²€ìƒ‰ ì´ë ¥ ì €ì¥: {topic_name}")

