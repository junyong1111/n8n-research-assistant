"""
Semantic Scholar API í´ë¼ì´ì–¸íŠ¸
ê³µì‹ REST APIë¥¼ ì‚¬ìš©í•œ ë…¼ë¬¸ ê²€ìƒ‰ ì„œë¹„ìŠ¤
"""
from typing import List, Dict, Optional
import requests
from app.utils.logger import get_logger, log_execution_time
from app.config import settings
import time

logger = get_logger()


class SemanticScholarService:
    """Semantic Scholar API ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""

    BASE_URL = "https://api.semanticscholar.org/graph/v1"

    def __init__(self, api_key: Optional[str] = None):
        """
        ì´ˆê¸°í™”

        Args:
            api_key: Semantic Scholar API Key (ì„ íƒ)
                    Noneì´ë©´ í™˜ê²½ë³€ìˆ˜(.env)ì—ì„œ ìë™ìœ¼ë¡œ ì½ìŒ
                    ì—†ìœ¼ë©´: 100 requests/5ë¶„
                    ìˆìœ¼ë©´: 5,000 requests/5ë¶„
        """
        # API Key ìš°ì„ ìˆœìœ„: íŒŒë¼ë¯¸í„° > í™˜ê²½ë³€ìˆ˜
        self.api_key = api_key or settings.SEMANTIC_SCHOLAR_API_KEY
        self.session = requests.Session()

        # ê¸°ë³¸ í—¤ë” ì„¤ì • (User-Agent í•„ìˆ˜!)
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
            "Accept": "application/json"
        })

        # API Keyê°€ ìˆìœ¼ë©´ í—¤ë”ì— ì¶”ê°€
        if self.api_key:
            self.session.headers.update({"x-api-key": self.api_key})
            logger.info("âœ… API Keyë¡œ ì´ˆê¸°í™” (5,000 req/5min) ğŸš€")
        else:
            logger.info("âœ… ë¬´ë£Œ ë²„ì „ìœ¼ë¡œ ì´ˆê¸°í™” (100 req/5min) âš ï¸")

    @log_execution_time
    def search_papers(
        self,
        keyword: str,
        year_from: int = 2024,
        year_to: int = 2025,
        limit: int = 5,
        fields: Optional[List[str]] = None
    ) -> List[Dict]:
        """
        í‚¤ì›Œë“œë¡œ ë…¼ë¬¸ ê²€ìƒ‰

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            year_from: ì‹œì‘ ì—°ë„
            year_to: ì¢…ë£Œ ì—°ë„
            limit: ë°˜í™˜í•  ë…¼ë¬¸ ìˆ˜ (ìµœëŒ€ 100)
            fields: ê°€ì ¸ì˜¬ í•„ë“œ ë¦¬ìŠ¤íŠ¸

        Returns:
            ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            logger.info(f"ğŸ“š ë…¼ë¬¸ ê²€ìƒ‰ ì‹œì‘: keyword='{keyword}', year={year_from}-{year_to}")

            # ê¸°ë³¸ í•„ë“œ ì„¤ì •
            if fields is None:
                fields = [
                    "paperId",
                    "title",
                    "authors",
                    "year",
                    "venue",
                    "citationCount",
                    "url",
                    "abstract",
                    "externalIds",
                    "openAccessPdf"
                ]

            # API ì—”ë“œí¬ì¸íŠ¸
            url = f"{self.BASE_URL}/paper/search"

            # íŒŒë¼ë¯¸í„° ì„¤ì •
            params = {
                "query": keyword,
                "year": f"{year_from}-{year_to}",
                "limit": min(limit, 100),  # ìµœëŒ€ 100
                "fields": ",".join(fields)
            }

            # API ìš”ì²­ (ì¬ì‹œë„ ë¡œì§)
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    response = self.session.get(url, params=params, timeout=30)

                    # 429 Rate Limit ì²˜ë¦¬
                    if response.status_code == 429:
                        wait_time = (attempt + 1) * 10  # 10ì´ˆ, 20ì´ˆ, 30ì´ˆ
                        logger.warning(f"â³ Rate Limit ë„ë‹¬. {wait_time}ì´ˆ ëŒ€ê¸° ì¤‘... (ì‹œë„ {attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                        continue

                    response.raise_for_status()
                    break  # ì„±ê³µí•˜ë©´ ì¢…ë£Œ

                except requests.exceptions.HTTPError as e:
                    if attempt == max_retries - 1:  # ë§ˆì§€ë§‰ ì‹œë„
                        raise
                    logger.warning(f"ìš”ì²­ ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘... ({attempt + 1}/{max_retries})")
                    time.sleep(5)

            data = response.json()
            papers = data.get("data", [])

            if not papers:
                logger.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []

            # ë…¼ë¬¸ ì •ë³´ ë³€í™˜
            result_papers = []
            for paper in papers:
                try:
                    converted = self._convert_paper_format(paper)
                    result_papers.append(converted)
                    logger.info(f"âœ… [{len(result_papers)}] {converted['title'][:60]}... (ì¸ìš©: {converted['citations']})")
                except Exception as e:
                    logger.warning(f"ë…¼ë¬¸ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue

            # Citation ìˆ˜ ê¸°ì¤€ ì •ë ¬
            result_papers.sort(key=lambda x: x.get('citations', 0), reverse=True)

            logger.info(f"ğŸ‰ ê²€ìƒ‰ ì™„ë£Œ: ì´ {len(result_papers)}ê°œ ë…¼ë¬¸")
            return result_papers

        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {e}")
            raise Exception(f"Semantic Scholar API ì˜¤ë¥˜: {str(e)}")
        except Exception as e:
            logger.error(f"âŒ ë…¼ë¬¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            raise

    def _convert_paper_format(self, paper: Dict) -> Dict:
        """Semantic Scholar ì‘ë‹µì„ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""

        # ì €ì ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        authors = []
        for author in paper.get("authors", []):
            if author.get("name"):
                authors.append(author["name"])

        # DOI ì¶”ì¶œ
        external_ids = paper.get("externalIds", {})
        doi = external_ids.get("DOI")

        # PDF URL ì¶”ì¶œ
        pdf_url = None
        open_access = paper.get("openAccessPdf")
        if open_access and open_access.get("url"):
            pdf_url = open_access["url"]

        return {
            "id": paper.get("paperId", ""),
            "title": paper.get("title", ""),
            "authors": authors,
            "year": paper.get("year"),
            "venue": paper.get("venue", ""),
            "citations": paper.get("citationCount", 0),
            "url": paper.get("url", ""),
            "abstract": paper.get("abstract", ""),
            "doi": doi,
            "pdf_url": pdf_url,
        }

    def get_paper_by_id(self, paper_id: str, fields: Optional[List[str]] = None) -> Optional[Dict]:
        """
        ë…¼ë¬¸ IDë¡œ ìƒì„¸ ì •ë³´ ì¡°íšŒ

        Args:
            paper_id: Semantic Scholar Paper ID
            fields: ê°€ì ¸ì˜¬ í•„ë“œ ë¦¬ìŠ¤íŠ¸

        Returns:
            ë…¼ë¬¸ ì •ë³´
        """
        try:
            logger.info(f"ë…¼ë¬¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ: {paper_id}")

            # ê¸°ë³¸ í•„ë“œ
            if fields is None:
                fields = [
                    "paperId", "title", "authors", "year", "venue",
                    "citationCount", "url", "abstract", "externalIds",
                    "openAccessPdf", "references", "citations"
                ]

            # API ìš”ì²­
            url = f"{self.BASE_URL}/paper/{paper_id}"
            params = {"fields": ",".join(fields)}

            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()

            paper = response.json()
            return self._convert_paper_format(paper)

        except Exception as e:
            logger.error(f"ë…¼ë¬¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def bulk_search_papers(
        self,
        keywords: List[str],
        year_from: int = 2024,
        year_to: int = 2025,
        limit_per_keyword: int = 5
    ) -> Dict[str, List[Dict]]:
        """
        ì—¬ëŸ¬ í‚¤ì›Œë“œë¡œ ë™ì‹œ ê²€ìƒ‰

        Args:
            keywords: ê²€ìƒ‰ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            year_from: ì‹œì‘ ì—°ë„
            year_to: ì¢…ë£Œ ì—°ë„
            limit_per_keyword: í‚¤ì›Œë“œë‹¹ ë…¼ë¬¸ ìˆ˜

        Returns:
            í‚¤ì›Œë“œë³„ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        results = {}

        for keyword in keywords:
            try:
                papers = self.search_papers(
                    keyword=keyword,
                    year_from=year_from,
                    year_to=year_to,
                    limit=limit_per_keyword
                )
                results[keyword] = papers

                # Rate Limiting ë°©ì§€ (ë¬´ë£Œ: 100 req/5min)
                time.sleep(0.5)

            except Exception as e:
                logger.error(f"í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                results[keyword] = []

        return results

